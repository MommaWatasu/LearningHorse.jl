# Horse.jl 日本語版マニュアル

Horseは使いやすく、高速な機械学習ライブラリを提供します。現時点では、回帰による学習に限られていますが、これから徐々に拡張していきます。

## インストール
Horseは今のところ名前でインストールする事はできません、次のようにする必要があります。
```@example
pkg > add https://github.com/QGMW22/Horse/Horse.jl
```

## 使い方

### SGDの使い方
勾配最急下法（SGD）は以下のようにして使うことができます

```@example
using Horse
x = [15.43 23.01 5.0 12.56 8.67 7.31 9.66 13.64 14.92 18.47 15.48 22.1 26.95 5.68 21.76]
t = [170.91 160.68 129.0 159.7 155.46 140.56 153.65 159.43 164.7 169.71 173.29 159.31 171.52 138.96 165.87]
w = Linear_Regression.SGD.fit(x, t)
println(w) #[1.539947 136.176160] 一つ目の要素が傾き、二つ目の要素が切片を表す。
```

引数は次の通りです。ただし、x, t以外はキーワード引数となっています。（）内はデフォルト値
- Linear_Regression.SGD.fit(x=[従属変数], t = [目的変数], alpha = (0.001)[学習率], tau_max = (100000)[繰り返しの最大数], eps = (0.1)[繰り返しをやめる勾配の絶対値の閾値])
返り値は、Array型で返されます。

構築したモデルを使った予測は以下の関数で行えます。
- Linear_Regression.SGD.predict(x = [従属変数], w = [フィットして得られたwのArray])

### 重回帰の使い方
重回帰は以下のようにして使うことができます。

```@example
using Horse
x =[15.43 23.01 5.0 12.56 8.67 7.31 9.66 13.64 14.92 18.47 15.48 22.13 10.11 26.95 5.68 21.76; 70.43 58.15 37.22 56.51 57.32 40.84 57.79 56.94 63.03 65.69 62.33 64.95 57.73 66.89 46.68 61.08]
t = [170.91 160.68 129.0 159.7 155.46 140.56 153.65 159.43 164.7 169.65 160.71 173.29 159.31 171.52 138.96 165.87]
w = Linear_Regression.MR.fit(x, t) #ここでは、逆行列が存在しないため、Errorが出る
println(w)
```

重回帰では、プログラム内で逆行列を生成できなかった場合、以下のようなErrorを返します。
```@example
Perhaps the matrix x you passed does not have an inverse matrix. In that case, use ridge regression.
```

エラー文の通りリッジ回帰を使うのも一つの手段ではありますが、いずれにしても固有値が0に近いことは事実であるが故に、不安定なモデルになってしまうため、相関の高いデータを一列残して削除することで解決する等の手段も考ると良いです。

引数は以下の通りです。ただし、x, tはキーワード引数ではありません。
- Linear_Regression.MR.fit(x = [従属変数], t = [目的変数])
返り値はArray型で返され、一つ目の要素がモデルの切片、それ以降はそれぞれの従属変数の係数となっています。

構築したモデルを使った予測は以下の関数で行えます。
- Linear_Regression.MR.predict(x = [従属変数], w = [フィットして得られたwのArray])
返り値はArray型で返されます。

### リッジ回帰の使い方
リッジ回帰は以下のようにして使うことができます。

```@example
using Horse
x =[15.43 23.01 5.0 12.56 8.67 7.31 9.66 13.64 14.92 18.47 15.48 22.13 10.11 26.95 5.68 21.76; 70.43 58.15 37.22 56.51 57.32 40.84 57.79 56.94 63.03 65.69 62.33 64.95 57.73 66.89 46.68 61.08]
t = [170.91 160.68 129.0 159.7 155.46 140.56 153.65 159.43 164.7 169.65 160.71 173.29 159.31 171.52 138.96 165.87]
w = Linear_Regression.RR.fit(x, t)
println(w) #[65.47458454192515; 0.1042034860770639; 1.5756199878279644] 一つ目の要素が切片、二つ以降の要素は従属変数xの係数を表す
```

引数は以下の通りです。ただし、x, tはキーワード引数ではありません。（）内はデフォルト値
- Linear_Regression.RR.fit(x = [従属変数], t = [目的変数], alpha = (0.1)[学習率])
戻り値はArray型で返され、一つ目の要素がモデルの切片、二つ目以降の要素は従属変数xの係数を表します。

構築したモデルを使った予測は以下の関数で行えます。
- Linear_Regression.RR.predict(x = [従属変数], w = [フィットして得たwのArray])
返り値はArray型で返されます。

### ラッソ回帰の使い方
ラッソ回帰は以下のようにして使うことができます。

```@example
using Horse
x =[15.43 23.01 5.0 12.56 8.67 7.31 9.66 13.64 14.92 18.47 15.48 22.13 10.11 26.95 5.68 21.76; 70.43 58.15 37.22 56.51 57.32 40.84 57.79 56.94 63.03 65.69 62.33 64.95 57.73 66.89 46.68 61.08]
t = [170.91 160.68 129.0 159.7 155.46 140.56 153.65 159.43 164.7 169.65 160.71 173.29 159.31 171.52 138.96 165.87]
w = Linear_Regression.LR.fit(x, t)
println(w) # [144.61846209854855, 0.951158307335192, 0.0] 一つ目の要素が切片、二つ目以降が従属変数xの係数を表す
```

引数は以下の通りです。ただし、x, tはキーワード引数ではありません。（）内はデフォルト値
- Linear_Regression.LR.fit(x = [従属変数], t = [目的変数], alpha = (0.1)[学習率], tol = (0.0001)[繰り返しをやめる誤差の絶対値の闘値], mi = (1000000)[繰り返しの最大数] )
戻り値はArray型で返され、一つ目の要素はモデルの切片、二つ目以降が従属変数xの係数を表します。

構築したモデルを使った予測は以下の関数で行えます。ただし、x, wはキーワード引数ではありません。
- Linear_Regression.LR.predict(x = [従属変数], w = [フィットして得られたwのArray])
返り値はLinearAlgebra.Adjoint型で返されます。

### MSE（平均二乗誤差）の使い方
平均二乗誤差は以下のようにして使うことができます。
```@example
using Horse
mean = Loss_Function.MSE([1, 2, 3, 4], [1, 2, 3, 4], [1, 2])
println(mean) #4
```

引数は以下の通りです。ただし、x, t, wはキーワード引数ではありません。
Loss_Function.MSE(x = [従属変数], t = [目的変数], w = [モデル])
返り値はFloat型です。また、モデルwは、一つ目の要素が切片、二つ目以降が従属変数xの係数となるように渡します。